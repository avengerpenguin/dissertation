\chapter{Conclusions and Future Work}

This chapter lays out some conclusions from this research around the potential
for semantics being used more in the enterprise, whether semantics combined
with machine learning or data mining has potential in industry and how
organisations should consider implementing this. Finally, some options and
potential for future research are suggested.

\section{Challenges and Opportunities for Semantics in the Enterprise}

As discussed in section~\ref{sec:production-recommendations} and also more
generally throughout chapter~\ref{chp:analysis}, there is much scope for
enterprises to benefit from using semantics in public-facing pages that display
their own content. This is particularly necessary in larger organisations where
attempting to gain an overview of all the content metadata in a short timeframe
would be a large enterprise integration effort.

The challenges amount to the issues raised around noise (semantic information
not immediately relevant to the content), incomplete information (due to
the open world assumption) and perhaps even erroneous information (embedded
Semantic Web data is not always visible enough for publishers to spot errors.)

Even with these issues, the experiment performed in this research was still
able to take place across a wide range of BBC content without any bespoke
integration against internal data APIs nor a any significant code created
to deal with a particular data source.

The power to use semantics and other web standards to gain a broad overview
of a large set of content should be very appealing to a media organisation,
even if there are issues with that data, assuming their application is in
a use case where less precision of that information is tolerable.

Even where data needed corrected, the software developed even in this
experiment was able to adapt to broad patterns in the data that were
problematic. there is also much indication that engineers in the enterprise
would be to complement the breadth from extracting semantics with the depth
of data obtained directly from data sources. This is achievable with the
set-theoretic nature of RDF graphs and our ability to perform simple set
union operations to join data sources.

As is evidenced by the pressure from social media and networks such as
Facebook and Twitter, publishers will include better semantics if the right
incentives are there. Perhaps the incentives promised by the earlier semantic
web advocates (search engine optimisation, the development of clients that
join up data between websites, etc.) were not strong enough for publishers,
but the need to control how that content is summarised and discovered in
places outside of the primary website is indeed a strong incentive.

There is much to be said for the argument that any enterprise that therefore
creates applied features to make use of content metadata (promoting related
content being just one example), that the organisation might create appropriate
pressure internally for those publishers to "correct" or at least improve
their semantic annotations when faced with clear evidence where improvements
could be made and errors corrected.

\section{Suitability for Semantics and Data Mining in Media Organisations}

As noted in section~\ref{sec:impact-of-noise}, the fuzzy and noisy nature
of linked data and the semantic web might find an ideal match in the world
of machine learning -- something that an operate on noisy and fuzzy data sets
and still find patterns and insight. That machine learning and data mining
builds upon the idea that data collected might be noisy or incomplete leads
to a strong argument for its application being ideal for the RDF model of
the semantic web.

Statistical methods like machine learning are clearly more tolerant of errors
than more ``hard'' uses such as presenting concrete facts to users based on
embedded semantics or inferring some hierarchical structure for a navigation
feature. Even where the machine learning methods struggle in this particular
research, it does not prevent further research that better tunes the learning
methods used to produce even more useful results.

The question remaining from all of this for the media enterprise, is whether
this combination of semantics and data mining has real application that is
useful.

The results of the survey discussed in chapter~\ref{chp:evaluation}
suggest the example application of driving related content suggests
was successful enough to get positive feedback for certain permutations
of the data pipeline. It was argued in analysis of the results that
there is a strong cost-benefit justification in creating a
general-purpose system capable of using embedded semantics on which
a clustering process can at least learn basic categorical structure.
This can then be made more nuanced and topic-drive over time with
entity extraction, when introduced in a supervised way so that it can
be tuned to behave desirably.

The development time on the extraction of embedded semantics is
far less than a series of bespoke enterprise integration efforts
against each data store and there are immediate results in some
of the clusters it can produce.

There is still much need for further research to improve these
extraction processes however. This is discussed in section~\ref{sec:con-future}.

\section{Future Research}
\label{sec:con-future}
\subsection{Better Enrichment}

As discussed in chapter~\ref{chp:evaluation}, enrichment by
deference fell down on some of the drawbacks of extraction via
dereference and did not seem to add much value to the clusters
produced.

The data pipeline designed theoretically in chapter~\ref{chp:design}
described many more suggestions for how we might enrich RDF graphs
in the middle of the pipeline, but this research only allowed time
to experiment with the simplest to implement.

One idea that could have a lot of potential is using OWL and RDFS
ontologies to infer facts not outright stated, which can find
generalisations (e.g. an article about tigers and an article about
lions are both about big cats even if we cannot find the word ``cat''
in their respective text content). Where the application in an
enterprise may be truly powerful is how such reasoning opens up
possibilities to include bespoke business rules to complement the
basic inferences. Here, there are possibilities to find a
balanced compromise from avoiding writing bespoke software to
transform multiple types of content, but still allow for experts
within the organisation to codify their knowledge and guide how the
data is transformed and enriched.

\subsection{Patterns for Reducing Data Noise}

The idea of bespoke inference rules in the previous section can help
reduce noise, but there may be great scope for experimental research
into more generally-applicable ways to strip out semantics we can
broadly identify as not useful for machine learning.

There may be trends or patterns in which vocabularies provide the
most useful data as well. The RDFS and OWL vocabularies focus on
describing ontologies, class hierarchies and schemas, which is more
abstract than describing the actual content and entities therein. Such
research might be able to confirm this is the case and we can indeed
cut back or filter out entirely such vocabularies in favour of, say,
Schema.org that is well-used for describing web content.

\subsection{Deeper Study of Machine Learning on Semantics}

This research presented only clustering as the machine learning
process used for experimentation as the focus was primarily on the
data pipeline upstream of the machine learning itself. Further
research could repeat the same data extraction processes, but explore
which other machine learning algorithms can provide useful insight
into an organisation's content.

Supervised learning techniques could start from known groups of
related content and be trained to identify more of such groups.
Association rule mining could find trends and patterns within
the content.
